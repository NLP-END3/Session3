{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session3_Pytorch101_ver2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPEdZ748BcpiP4Dzf1bEfYR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phaninandula/phaninandula-END3-session1/blob/main/Session3_Pytorch101_ver3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCYKM8CvKPwH"
      },
      "source": [
        "## Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEdgomGU6sBv"
      },
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT8ngkwfbEmy"
      },
      "source": [
        "## Checking for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yhC-FvuIVxK",
        "outputId": "a29f2afc-290a-4fbc-ebcc-ad0b55c77264"
      },
      "source": [
        "print(torch.cuda.is_available())  # Checks if GPU is available\n",
        "print(torch.cuda.get_device_name(0)) # Name of GPU\n",
        "print(torch.cuda.device_count())\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla K80\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGpC3QGI7NJU"
      },
      "source": [
        "# Importing MNIST dataset from pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l4RLz-c7MOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adde0dbb-c777-4285-c746-519ab6b351eb"
      },
      "source": [
        "mnist_train = datasets.MNIST('../data',train=True,download=True,transform=transforms.Compose([transforms.ToTensor()])) # Train dataset\n",
        "mnist_test = datasets.MNIST('./data',train=False,download=True,transform=transforms.Compose([transforms.ToTensor()])) # Test dataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjmKTyJOLrAv"
      },
      "source": [
        "## Plotting few samples of the downloaded data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "a3AX1A3jLqV8",
        "outputId": "8c3bc405-0778-466b-805b-7fefa3c4f31c"
      },
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(mnist_train), size=(1,)).item()\n",
        "    img, label = mnist_train[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAAHRCAYAAAABukKHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de9xOVdrA8WsJDZ6QU4rKS6UhjRoqFapB480gIo0KaXyKSk0nHU10NooURooOpmjSW1M5h2R0UMlHpejslIfocRb2+4d639Ze+3r2/Wz7vvf93Pfv+/n4zFzXs/baq1ruy7bWvbbxPE8AAICrTNIDAAAgW1EkAQBQUCQBAFBQJAEAUFAkAQBQUCQBAFBQJAEAUFAkfYwxW32/9hpjRiU9LuQ+Y0w1Y8xLxphtxphvjDF/TnpMyG3MuXBlkx5AtvE8r+CX/2+MKRCRdSLyQnIjQh55TER2i8hhItJURF4zxnzked7HyQ4LOYw5F8Jw4o7OGNNLRAaLSAOPf1FII2NMJRHZJCIneJ73+c+5Z0Rkted5gxIdHHIScy41/HVr8XqJyNMUSGTAcSKy55cPq599JCKNExoPch9zLgUUSYUx5mgRaS0iTyU9FuSFAhEp8uV+FJFDEhgL8gNzLgUUSd0lIvKW53lfJT0Q5IWtIlLZl6ssIlsSGAvyA3MuBRRJ3aXCUyQy53MRKWuMOfZXud+JCBsokC7MuRSwcSeAMeZ0EZklIrU9z+NPVcgIY8zzIuKJyOWyf6fh6yJyOjsNkS7MuXA8SQbrJSJTKZDIsP4iUkFE1ovIcyJyJR9WSDPmXAieJAEAUPAkCQCAgiIJAICCIgkAgIIiCQCAgiIJAICi2LeAGGPY+prHPM8zSdyXeZffkph3zLn8Vtyc40kSAAAFRRIAAAVFEgAABUUSAAAFRRIAAAVFEgAABUUSAAAFRRIAAAVFEgAABUUSAAAFRRIAAAVFEgAABUUSAAAFRRIAAAVFEgAABUUSAAAFRRIAAEXZpAcAID2aNm3q5IYMGWLFZ511ltPm8ssvd3JTpkyJbVxAacKTJAAACookAAAKiiQAAAqKJAAACuN5nv5DY/QfIud5nmeSuC/zLlyZMu6fb0ePHm3Fffv2ddqULRu+V2/Tpk1O7vjjj7fi9evXh/YTVRLzLp/m3MEHH+zkpk2b5uTOPvtsK963b5/T5v7777fioE1fNWrUCB1TYWGhk2vTpo0VL1u2LLSfqIqbczxJAgCgoEgCAKCgSAIAoGBNEirWJLNH3bp1rfjll1922px88smx3GvNmjVOrk6dOrH0nQrWJON1/vnnW/GECROcNgUFBU7OGPs/Q3G1Ih38697t2rVz2sS1TsmaJAAAEVAkAQBQUCQBAFBQJAEAUCT2FpBDDjkktM2WLVsyMJKS+c1vfmPFFStWdNr4F5jPPfdcp82GDRus2P92BpHs/OdHvIK+2N2lSxcnN2LECCuuVatW2sYU9Hvz6KOPtuJvvvkmbfdHvDp16mTFQZt0spF/jrds2dJpk84DBn7BkyQAAAqKJAAACookAAAKiiQAAIqMbNwpX768k3vhhResuFGjRk6b6dOnO7mxY8dacZMmTZw2Z5xxRkmHmDL//U499dRY+q1Xr56T69atWyx9I3t1797dyT399NOR+po6daoVP/PMM06bJ5980ooPPfRQp03Qxh3/5o9HHnkkyhCRZvXr13dyHTt2jKXvV1991cndfffdVpzKZsPx48c7uRYtWkQfWJrxJAkAgIIiCQCAgiIJAIAiI2uShx12mJNr3ry5FQetjQS95Tool6TVq1c7Of9bFBo0aOC0qVatWtrGhOzlfyPD448/ntJ127dvt+J+/fo5bSZNmhTaj//t8kFvEwly1113WTFrktmhcePGVhw0BypXrhyp76eeesqK//KXvzht9u7dG9pPs2bNrNg/5mzHkyQAAAqKJAAACookAAAKiiQAAIqMbNz57rvvnFzr1q2tuGbNmin1dd9991nxKaec4rRZvny5Fcf5xoJHH33Uij/++GOnzY4dO6z4o48+iu3+KD06d+7s5CZPnmzF5cqVc9r4N+mIuF8InzNnTqQxBR3skYoHH3ww0nVIr+OOO86KTzjhhEj9rFq1ysndc889VpzKJp0gVapUseKoG4mSwpMkAAAKiiQAAAqKJAAAioysSQaJ+kbpDh06WHGdOnWcNv4v8xcWFka6V1RHHXWUFafyFvmJEyemaTTIFP9h9y+++KLTpkwZ+8+lW7duddoEHUg9d+7cAxzdfjfeeGOk6xYuXBjL/RFdmzZtnNzo0aNL3I9/z4SISLt27ZzcF198UeK+gw7H79u3b4n7ERHZuHGjFU+bNi1SPweKJ0kAABQUSQAAFBRJAAAUFEkAABSJbdyJasOGDcXG2eDkk08ObePfCDFr1qx0DQdp4H+bh4jI008/bcX+TToi7pvbu3Tp4rSJa5NO1apVnZz/y+dBdu/e7eSKiopiGRNSV6FCBSt+4IEHnDapHMLiPwRg/PjxTpvPP/+8hKMLFrS5qHv37pH6Wr9+vRV//fXXkfo5UDxJAgCgoEgCAKCgSAIAoCh1a5LZxhjj5M4999zQ6/zrC0HrQMgeZ555phU//PDDTpuCggIrDjoowL8GOXv27BhGF2zUqFFOLmid0m/48OFObsmSJbGMCanr1KmTFf/ud7+L1M+4ceOs+Lrrros8pjAHH3xwpOv27dvn5PwHrCeFJ0kAABQUSQAAFBRJAAAUFEkAABTG8zz9h8boP4SIiNSuXdvJ+d9CEqR9+/ZWPGPGjNjGFBfP89xdSRmQ9Lw78sgjndzrr79uxUFvgN++fbsV+99YIxLfQQFBG8bOOOOM0HuVLWvv1fv222+dNi1atHByqczpuCQx75Kec0EHkEyfPt2Kq1WrFtpP0BuP2rZta8VR38CUio8//tjJNWzYMPS6Tz/91Mk1adIkljGlorg5x5MkAAAKiiQAAAqKJAAACookAAAKTtw5QAMGDAhts2vXLicXdBoLMs+/kUVE5MEHH3RyQRt1/IYNG2bFcW3SCRJ0+sqCBQtCr/O/EaJr165Om0xu0sF+QfOrevXqJe5n6tSpTi6dG3WeeOIJKz7++OMj9fPmm2/GMZy04EkSAAAFRRIAAAVFEgAABWuSB6hOnTpOzv9F76A3PSxcuDBtY0LqBg4c6OR69OgRet2rr77q5P72t7/FMaTAgwL8a5CpvD0k6M0K/jX0xYsXl3B0SIc777zTyRV30Msv3n//fSsOms9xOfHEE51c586drTjKmEXSO+4DxZMkAAAKiiQAAAqKJAAACookAAAKNu6UkH9TR69evZw2/rdB+L9kjuzRvHnzlNr5v5Ddt2/fdAxHRERuvvlmJ3ffffeFXrd27VorbtWqldNm5cqV0QeGWPTp08fJBb15JhX+wyH27NkTqZ8g/gMOgt5UVKVKlRL3e++99zq5OMcdN54kAQBQUCQBAFBQJAEAULAmWUJ33HGHFQd98XvDhg1WnM2H9+abG2+80YovvPDClK6bNGmSFa9fvz7S/Y855hgrnjx5stPmpJNOCu1n1apVTq5BgwZWvHv37hKODplw6623OrmDDjoo9LrCwkInd9ttt5X4/uXKlXNyI0eOdHL+w++jHLgu4h6CnspBGNmEJ0kAABQUSQAAFBRJAAAUFEkAABRs3CmhVBavH3300QyMBFH4N84E8W+8EhGZOHFiie/VqVMnJzdu3DgrrlWrVkp9zZkzx4q7dOnitGGjTulQs2bNSNe99NJLTm7u3Lmh1zVu3NiKr7jiCqdNv379nJx/U2Iqb/jwb9IREfnrX/9qxdu2bQvtJ5vwJAkAgIIiCQCAgiIJAICCNcli+NePRNw1pKB1oFTWCZCMjh07hrZ55plnnNy6deus+Oyzz3ba9O7d24ovvfTS0Hvt2rXLyQUdMHDDDTdYcVFRUWjfyC1PPvmkkysoKLDi1q1bO23Gjh1rxYcffnik+3///fdOrn///lYcdFBAaVuD9ONJEgAABUUSAAAFRRIAAAVFEgAAhSnuC6LGmPBvj+aIE0880cnNmzfPyVWtWtWKg77g6z89v7TyPM99xUkGpHPebdmyxYr9Gx9EgjcoLFq0yIrbtGnjtAnqy2/lypVWPGjQIKfNiy++GNpPLkti3mXys27z5s1OLpW5M3/+fCfn/8J/q1atog/Mx//ZNnToUKfN0qVLY7tfkoqbczxJAgCgoEgCAKCgSAIAoKBIAgCg4MSdn51yyilOzr9JJ8iMGTPSMRykiX/jTNOmTZ02hx12mJPr3LlzaN979uyx4kmTJjltbr31Vites2ZNaL+ASPBpOlHs27fPyQW95Wb06NFWnCubdEqKJ0kAABQUSQAAFBRJAAAUeXuYgH+9ccGCBU4b/xu9RUS+++47K27QoIHTxr82VVrl4mEC/kMjBg4c6LTp1q2bk/OvHb733ntOmxEjRljx+++/H2WIeS/XDxPwf4aIBK+DlykTzzOM/3CMwYMHO23Gjx8fy71KKw4TAAAgAookAAAKiiQAAAqKJAAAirzduNO3b18rfvzxx1O67uSTT7biJUuWxDambJOLG3eQ/XJ9406QoI0zvXv3Dr1u1apVVjxmzBinzWuvvWbFy5YtK9ng8gAbdwAAiIAiCQCAgiIJAIAib9ckX3nlFSvu0KGD02bFihVOrnnz5lZcVFQU78CyCGuSSEI+rkkiWaxJAgAQAUUSAAAFRRIAAAVFEgAARdmkB5At/G+sFxFp27atk8vljToAABtPkgAAKCiSAAAoKJIAACjy9jABhOMwASSBwwSQaRwmAABABBRJAAAUFEkAABQUSQAAFMVu3AEAIJ/xJAkAgIIiCQCAgiIJAICCIgkAgIIiCQCAgiIJAICCIgkAgIIiCQCAgiIJAICCIgkAgIIiqTDG9DDGfGqM2WaM+cIY0zLpMSG3GWOeNcasNcYUGWM+N8ZcnvSYkNuYc+E4uzWAMaatiIwXkQtF5F0ROVxExPO81UmOC7nNGNNYRFZ6nrfLGHO8iMwTkfM8z3s/2ZEhVzHnwvEkGewuERnied7bnuft8zxvNQUS6eZ53see5+36Jfz5V4MEh4Qcx5wLR5H0McYcJCLNRKSmMWalMWaVMeZRY0yFpMeG3GeMGW2M2S4iy0VkrYi8nvCQkOOYc8WjSLoOE5FyInKBiLQUkaYicpKI3J7koJAfPM/rLyKHyP65N1VEdhV/BXBgmHPFo0i6dvz8v6M8z1vred4GEXlIRP47wTEhj3iet9fzvLdEpK6IXJn0eJD7mHM6iqSP53mbRGSV7P+7+f9LJzQc5LeywvoQMos550ORDDZBRK42xtQyxhwqIteJyKsJjwk57Oe51sMYU2CMOcgYc66IXCQic5IeG3ITcy41fAUkgDGmnIiMFJE/i8hOEZkiIjd5nrcz0YEhZxljaorIv0Tkd7L/D6/fiMgjnuc9nujAkLOYc6mhSAIAoOCvWwEAUFAkAQBQUCQBAFBQJAEAUJQt7ofGGHb15DHP80wS92Xe5bck5h1zLr8VN+d4kgQAQEGRBABAQZEEAEBBkQQAQEGRBABAQZEEAEBBkQQAQEGRBABAQZEEAEBBkQQAQEGRBABAQZEEAEBBkQQAQFHsW0AQ7sgjj3RyDz30kBVfcMEFTpsxY8ZY8eTJk5028+fPP8DRAQAOBE+SAAAoKJIAACgokgAAKIzn6S/k5m3drrp161rxjBkznDbHH398ifvdtGmTkwtay5w3b16J+44qiTfEizDv8l0S8445l9+Km3M8SQIAoKBIAgCgoEgCAKCgSAIAoOAwgZ8Z467bXnbZZU7u3nvvteIaNWrEcv9DDz3UyXXv3t3JZXLjTr668847ndzgwYOtOGi++DfBTZgwwWnTqlUrK27QoIHTJuhgiWbNmlnxRRdd5LRZsWKFFRcVFTltAJQMT5IAACgokgAAKCiSAAAo8nZNskqVKlYctMbz2GOPpe3+AwcOtOI2bdo4bdatW5e2+0O3ZcsWJ+df36tcubLTxr8m2bt379B7BR3mceGFF4a2e+edd5w2I0aMsOIhQ4Y4bVinLD38c+ycc85x2gwbNsyKg9a4/evnxR0g82sVK1a04p07d6Z0Xa7hSRIAAAVFEgAABUUSAAAFRRIAAEXevgXklltuseK77747tr43btxoxQMGDHDaTJ061Yr37t0b2/3jwltA/p//sIeyZePZ83bCCSc4Of+BAyLuZougOVW9enUrHjNmjNPmpptusuIdO3akNM5Myse3gPTo0cPJ+Q8T6dSpU6aGIyIizzzzjBU/9dRTTpu5c+dmajhpxVtAAACIgCIJAICCIgkAgIIiCQCAIic37vhPmPCfRCIi0q9fPysuX758pHstWLDAyQ0aNMiK33777Uh9J42NO9mrUaNGTu4f//iHFbdo0cJpc/XVV1tx0OaepOX6xp3TTz/dyc2ePdvJHXzwwZkYTsqCNouNHTs2gZHEj407AABEQJEEAEBBkQQAQJGTbwHxr0FeddVVsfX9yiuvWPFdd93ltFmyZEls9wOCfPLJJ05uzZo1odf533aTjWuSuS7oIIpsW38UEfnss8+seNGiRQmNJFk8SQIAoKBIAgCgoEgCAKCgSAIAoCj1hwm0bt3ayU2fPt2Kox4U8M477zi5Sy65xIq/+OKLSH2XBhwmkH7VqlVLqV3lypWt+Prrr3fa9O/fP7Qf/4afJk2apHT/TMr1wwQqVKjg5A4//PBIfTVv3tyK//nPf0bqJ0j9+vWt+Jtvvomt72zDYQIAAERAkQQAQEGRBABAUerWJGvVqmXFc+bMcdoEHf4cprCw0MnVq1fPye3cubPEfZdWrEkemI4dOzq5P/3pT1bcsmVLp43/gH4RkRo1alhxlSpVQu8ftF7es2dPK168eHFoP5mW62uScXr33Xet+Pe//31sfVeqVMmKc/mzjzVJAAAioEgCAKCgSAIAoKBIAgCgyOq3gJQp49bwa6+91oqjbNIRcd/mMXToUKdNu3btnNwFF1wQ2vfatWuteOrUqaHXrFixwsn98MMPodchfv45JiIyaNAgKw7aXOPfBFe9enWnTdB1qbTx9z1t2jSnzXvvvVdsLJKdG3WQmkMOOcTJlStXLm33q127thX/9NNPTpvdu3dbcdAGyNKOJ0kAABQUSQAAFBRJAAAUWX2YwJAhQ5zcbbfdVuJ+NmzY4OSeffZZKw46KP2kk04q8b2iWrlypZMLWhsLWotKl3w9TGDy5MlOrmvXrlacyrphVKn0HXQgdq6sB3GYwH7+Ne0nn3zSadOhQ4dMDSeQ/9DzYcOGOW2KioqseNKkSWkdUxQcJgAAQAQUSQAAFBRJAAAUFEkAABRZs3GnadOmTu6NN95wcqm8/SBX+L+oKyIyZcoUK+7Vq1fa7p+vG3f69u3r5Pzzs3///k4b/+armTNnht6rR48eTq5atWpOzv/7dPz48U6bK664IvR+pQEbd/YrKCiw4oceeshp07t3byvet2+f0yadBw6kYvv27VZ80003OW3GjRvn5Pbu3Zu2MfmxcQcAgAgokgAAKCiSAAAoKJIAACiyZuPO9OnTnVzbtm0zdfuUffTRR1Y8e/Zsp00qb1q4+uqrrfj0009P6f7btm2z4rPOOstp88EHH6TUV5h83biTtM6dOzu5kSNHWnHdunWdNhMmTLDiAQMGOG127dp1gKNLPzbupO7666+34qVLlzpt/Jt7ggR9/hx11FGRx1VSQSeevfXWWxm7Pxt3AACIgCIJAICCIgkAgII1yZ8FfXE/6Mu799xzjxX7vyibKv+akv80/VQFnah/6aWXRurLjzXJ7FGzZk0r9q9Rioh0797diidOnOi0ufzyy2MdVzqwJpl5p512mpM7+uijrbhPnz5Om7g+o1mTBACgFKJIAgCgoEgCAKCgSAIAoCib9ACSsmHDBit++OGHnTb3339/2u5/2GGHxdJPhQoVYukH2a2wsNCKL774YqeNMfbeg6AvkfvftvDuu+8e+OBQ6r399tuhualTpzptvv76ayuuXbt2rOPKBjxJAgCgoEgCAKCgSAIAoMiLNcnHHnvMyd11111WvHHjxtjuV7VqVSt+4IEHnDZBX8xNxc6dO614+PDhkfpB6Rb0BvprrrnGioMOrb711lutOOgwdSDITz/95OSC5mGu4UkSAAAFRRIAAAVFEgAABUUSAABF1mzcCfrifosWLZxcQUFBaF/+N3MMHjzYabNp06YSjO7/HXfccVZ83nnnOW2uuuoqK65Xr16kewWZPXu2FQd9CRj5yX/gwOOPP+60ufDCCzM1HOSYoM+x8uXLl7ifdevWObmtW7dGGVJG8CQJAICCIgkAgIIiCQCAImvWJOfNm+fkXn75ZSfXs2fP0L78f09+++23h17TvHlzJ3fqqac6uTJlyhQbR7V+/Xond+211zq5F154IZb7IX5VqlSx4m3btjlt9uzZk7b7V6pUyYp79erltDnmmGOsOOiN8PPnz493YCiV/HPlueeec9rUqFGjxP1OmjTJyS1ZsqTE/WQKT5IAACgokgAAKCiSAAAoKJIAACiM53n6D43Rf5gB9evXd3I33nijFffr1y9Tw4ls9erVTm78+PFW7H9jvEjwl24zyfM8E94qfknPu6i6detmxUGHYSxatCi0n1Q2ZzVr1szJ+efQiSee6LTZsmWLFZ9xxhlOm08++ST0/umUxLwrrXMunZYvX27Fxx57bKR+vv32WysO+n2RzZ91PEkCAKCgSAIAoKBIAgCgoEgCAKDI6o07QQ4//HArHjRoUOg1NWvWdHJR34bg31Tx/fffO22mT59uxR988IHTJui6bMPGnZJp3LixFQdt0qlYsWJoPxs3bnRy/t+nQf2k0vfVV19txWPGjAm9JtPYuJN5HTp0cHIvvviiFZctG+2AtuHDh1vxTTfdFKmfdGLjDgAAEVAkAQBQUCQBAFCUujVJZA5rkgeme/fuTm7kyJFWHLReboz7r72436e/8B8CMHfuXKfNwIEDQ/tJGmuS0Z1//vlOLuhtQn4NGzZ0ckFz02/z5s1WvG/fPqdNy5Ytrdh/SEE2YE0SAIAIKJIAACgokgAAKCiSAAAo2LgDFRt34le3bl0rfuSRR5w2nTp1cnL+36ejR4922tx+++1WXFRUFGWIiWPjTnRnn322k3v66aet+Igjjojtfv75vHbt2tj6ziQ27gAAEAFFEgAABUUSAAAFa5JQsSaJJLAmGa/WrVtb8RtvvOG0+fvf/+7kFi5cGNr3zJkzrXjnzp0lHF12YE0SAIAIKJIAACgokgAAKCiSAAAo2LgDFRt3kAQ27iDT2LgDAEAEFEkAABQUSQAAFBRJAAAUFEkAABQUSQAAFBRJAAAUFEkAABTFHiYAAEA+40kSAAAFRRIAAAVFEgAABUUSAAAFRRIAAAVFEgAABUUSAAAFRRIAAAVFEgAABUUSAAAFRbIYxphjjTE7jTHPJj0W5D5jTD1jzOvGmE3GmHXGmEeNMWWTHhdykzFmq+/XXmPMqKTHlW0oksV7TETeS3oQyBujRWS9iBwuIk1FpLWI9E90RMhZnucV/PJLRGqLyA4ReSHhYWUdiqTCGNNDRDaLyJykx4K88V8iMsXzvJ2e560Tkeki0jjhMSE/dJX9f0BbkPRAsg1FMoAxprKIDBGRvyY9FuSVESLSwxhT0RhTR0Tay/5CCaRbLxF52uO1UA6KZLChIvKE53mrkh4I8sqbsv/JsUhEVonIYhH5n0RHhJxnjDla9v/V/lNJjyUbUSR9jDFNRaSNiDyc9FiQP4wxZWT/U+NUEakkIjVE5FAReSDJcSEvXCIib3me91XSA8lGFEnXWSJST0S+NcasE5EbRKSrMeaDJAeFnFdNRI4SkUc9z9vled5GEZkgIv+d7LCQBy4VniJVhr+CthljKopI5V+lbpD9RfNKz/MKExkU8oIx5ksRGScifxeRAtlfJHd4nvfnRAeGnGWMOV1EZolIbc/ztiQ9nmzEk6SP53nbPc9b98svEdkqIjspkMiALiLyRxEpFJGVIvKTiFyX6IiQ63qJyFQKpI4nSQAAFDxJAgCgoEgCAKCgSAIAoKBIAgCgoEgCAKAo9jU8xhi2vuYxz/NMEvdl3uW3JOYdcy6/FTfneJIEAEBBkQQAQEGRBABAQZEEAEBBkQQAQEGRBABAQZEEAEBBkQQAQEGRBABAQZEEAEBBkQQAQEGRBABAQZEEAEBBkQQAQEGRBABAQZEEAEBBkQQAQEGRBABAQZEEAEBBkQQAQEGRBABAQZEEAEBRNukBpEPFihWteMCAAU6bypUrW/HQoUOdNrt3745lPPXq1XNy8+fPt+K6des6bRo2bOjkVq5cGcuYAADheJIEAEBBkQQAQEGRBABAUerXJE855RQn98orr1hxjRo1Qvu5//77nVxca5J9+vRxcnXq1LHiDz/80GlTWFgYy/2RPY4++mgrPuigg2Lr+/vvv7fibdu2xdY3kK94kgQAQEGRBABAQZEEAEBBkQQAQFHqNu5UqFDBikeNGuW08W/UKSoqctrccccdVhzXJh0Rd3NG7969Q69ZsWKFk/vxxx/jGhIOkH+j1W9/+9tI/fzrX/+yYv+hFgfizjvvtOIRI0Y4bbZu3Rqpb/+BGMccc0zoNQsXLnRyO3bsiHT/0uy4446z4nHjxjltrrjiCifn/0zYu3dvvAMroWrVqjm5ffv2WfHmzZszNZyM4UkSAAAFRRIAAAVFEgAABUUSAACF8TxP/6Ex+g8TcsEFF1jx888/77TxLx5fdNFFTptZs2bFO7Bfadq0qRUvXrw49JqLL77YyQX9s2WS53kmifsmPe/8m3RERO69914rvuSSSzI1nMiaNGni5D7++OPQ64I25QwbNsyKO3fuHNrPLbfc4uSCTrbyS2LepXPO+TdrdenSJaXr/J8jS5cujWU8lSpVcnLt2rVzcu3bt7fivn37Om22b99uxc8995zTZuTIkVacyhzMtOLmHE+SAAAoKJIAACgokgAAKLJ6TbJBgwZOzv8F5aA3fLzwwgtWHLQmmU5R1iSbNWvm5JYsWRLbmKLI1zXJNnoWKOQAAAc4SURBVG3aOLmZM2cmMJIDM378eCe3YcOG0OsaNWrk5Dp27GjFxoRPjaDPljJlwv9cnmtrkueff74VT5w40WlzyCGHOLkvv/zSiseMGeO0WbBgQej9u3btasVnnnmm06ZFixah/UQ1adIkK77yyiudNlEPuYgLa5IAAERAkQQAQEGRBABAQZEEAECR1W8BOemkk5ycf6NOYWGh0yZogRvIN5dffnna+i5uwx9sL730khXXrFnTaTN27FgnV79+fSv2H+gQp9WrVzu5ZcuWWfFbb73ltFm5cqUVBx0m0LNnTyv+97//7bSZMmVKSuNMAk+SAAAoKJIAACgokgAAKLJmTTLoy7TXXXdd6HXPPvusk3vzzTdjGVNUqby13n8owmeffZau4aCE3nvvPSd32mmnhV539913W3HQoQS5bMCAAVb8/vvvJzSS7Pbtt99m9H7+AySC9mw88cQTTi6VcR511FElHk+3bt2cHGuSAACUQhRJAAAUFEkAABQUSQAAFFmzcWfw4MFO7tRTTw297uWXX07HcA5IKm9t938xd8eOHekaDkroxx9/dHLvvvtu6HUbN25Mx3DSat++fU4ulbk4aNAgJ+ff/LF79+7oA8th8+fPd3Kffvqpk/NvABw5cqTT5qGHHgq9365du6x4/fr1odek0+jRoxO9f0nxJAkAgIIiCQCAgiIJAIAia9Ykv/jii0jXNWvWzMkFHcQbl/POO8+Ke/fu7bT54x//GNpP0MHsQKYFHZyQzrfUI3jN99JLL3Vyc+bMseKgA+tTOXAlLsYYJ3fDDTeEXvfll19a8eeffx7bmDKBJ0kAABQUSQAAFBRJAAAUFEkAABRZs3Fn1qxZka6rVKlSpOv8G37atm3rtDnrrLOcXKtWray4XLlyke7/hz/8wYpHjBgRqR+gJF577TUr/uSTTxIaCX4t6I0pRUVFVnzEEUc4bdq3b2/F06ZNi3dgv9KxY0cnd9VVV4Ve5387zOrVq2MbUybwJAkAgIIiCQCAgiIJAICCIgkAgCJrNu4ECTrhwW/IkCFOrl69elbcpUsXp03VqlVD+y5Txv0zRNBbE6JYsGBBLP0gM0444QQrbtOmjdOmYcOGmRpOZN27d7di3j6TvTZs2GDFdevWddo8+OCDVpzOjTtBp5vlA54kAQBQUCQBAFBQJAEAUGTNmuSePXucnP/v5EVEqlevHtpXnz59Qtt4nhfaZs2aNU5u5syZVlynTh2nzTnnnBPa93/+85/QNkhG0Nqi/7CHVP4bAwfCv5fC/9kjIjJ06NBMDSeQf99IKp+rpQ1PkgAAKCiSAAAoKJIAACgokgAAKLJm487XX3/t5Bo1auTk+vfvb8U9e/aMdL9Ro0ZZ8bZt25w2EydODO3n2muvdXL+TR1BX9jmS9zZoXbt2k5uwoQJTu60007LxHCA/+P/TAzaLLZq1aoMjSZYLm7U8eNJEgAABUUSAAAFRRIAAEXWrEkG2bhxo5Pzf3k26S/TNmnSJLRN0FvHg3LIvIoVKzq5XF5/9H8hvWXLlgmNBCWV9PpjKpYvX+7kFi5cmMBI4sOTJAAACookAAAKiiQAAAqKJAAAiqzeuJONypcvb8W1atUKvWby5MnpGg4O0IIFCxK9/2effebkhg8f7uTGjRsXy/2OPfbYWPoBguzatcvJbd26NYGRxIcnSQAAFBRJAAAUFEkAABSsSZZQ9erVrbh9+/ah13z11VfpGg4OUNCX6VeuXJmx+zds2NDJxbX+GOTDDz9MW99ALuJJEgAABUUSAAAFRRIAAAVFEgAABRt3Suiyyy5LeghASl577TUn17Vr1wRGglxljEl6CGnHkyQAAAqKJAAACookAAAKiiQAAAo27pRQKm/9QOmxefNmJzdp0iQn17NnTyueN2+e06ZmzZpW3Lhx4wMbXAlNmTLFiq+55hqnze7duzM1HOQBz/OSHkLa8SQJAICCIgkAgIIiCQCAgjVJ5LUffvjByd18881Ozr8GuXjxYqdNtWrVrLh+/fpOm/Lly1vxY4895rRZsmSJkwtq5zdr1iwrXr9+feg1QJwKCgqcnP/NSRs3bszUcGLBkyQAAAqKJAAACookAAAKiiQAAAo27pTQokWLrHjAgAFOm6VLl1rx7Nmz0zomxGvNmjVO7oknnihxP3PnznVyBx10kBUvX77caVNYWOjkli1bVuL7A5nWoEEDJ9esWTMrnjFjRqaGEwueJAEAUFAkAQBQUCQBAFCwJllCzz//fLExUJy9e/dacdC6JYDswZMkAAAKiiQAAAqKJAAACookAAAKNu4AAEK98847oW2C3jzz1VdfpWM4GcOTJAAACookAAAKiiQAAArjeZ7+Q2P0HyLneZ5nkrgv8y6/JTHvmHP5rbg5x5MkAAAKiiQAAAqKJAAACookAACKYjfuAACQz3iSBABAQZEEAEBBkQQAQEGRBABAQZEEAEBBkQQAQPG/MEGkqyEZKjEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhFULDhUmDqT"
      },
      "source": [
        "#dir(mnist_train)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KWhT4kdbOmn"
      },
      "source": [
        "## Checking the size of the image, label and image information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPFRfc0NUSMN",
        "outputId": "06acac63-cdd6-4a12-d979-529f87108f43"
      },
      "source": [
        "for im,la in mnist_train:\n",
        "  print(f'image : {im}')\n",
        "  print(f'label : {la}')\n",
        "  print(f'shape of image : {im.shape}')\n",
        "  break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image : tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
            "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
            "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
            "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
            "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
            "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
            "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
            "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
            "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
            "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
            "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
            "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
            "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
            "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
            "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
            "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
            "label : 5\n",
            "shape of image : torch.Size([1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "corC6wTAIXto",
        "outputId": "0b48d96b-5b76-4eee-8503-e5268c876fec"
      },
      "source": [
        "# Number of images in training and testing \n",
        "len(mnist_train), len(mnist_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvo-DfNHJbAb",
        "outputId": "95a5ba3e-3523-433d-b9e8-bd576895d933"
      },
      "source": [
        "print(dir(mnist_train))\n",
        "#mnist_train.train_labels\n",
        "\n",
        "print(f'Number of examples in training dataset :{len(mnist_train)}')\n",
        "print('\\n')\n",
        "print(f'Shape of the training dataset - images : {mnist_train.train_data.shape}')\n",
        "print('\\n')\n",
        "print(f'Labels in the training dataset : {mnist_train.train_labels}')\n",
        "print('\\n')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__add__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_check_exists', '_check_legacy_exist', '_format_transform_repr', '_load_data', '_load_legacy_data', '_repr_indent', 'class_to_idx', 'classes', 'data', 'download', 'extra_repr', 'mirrors', 'processed_folder', 'raw_folder', 'resources', 'root', 'target_transform', 'targets', 'test_data', 'test_file', 'test_labels', 'train', 'train_data', 'train_labels', 'training_file', 'transform', 'transforms']\n",
            "Number of examples in training dataset :60000\n",
            "\n",
            "\n",
            "Shape of the training dataset - images : torch.Size([60000, 28, 28])\n",
            "\n",
            "\n",
            "Labels in the training dataset : tensor([5, 0, 4,  ..., 5, 6, 8])\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:62: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:52: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH8C3z5QLjUy"
      },
      "source": [
        "# Creating training and testdata for random numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jaA7jaCLjCF"
      },
      "source": [
        "### Training & Testing #############################################\n",
        "def rand_num(min_num,max_num,data_size):\n",
        "  rand_num_label = torch.randint(min_num,max_num,(data_size,))\n",
        "  rand_num_one_hot = F.one_hot(rand_num_label)\n",
        "  return rand_num_label,rand_num_one_hot\n",
        "\n",
        "rand_num_train_label, rand_num_train_one_hot = rand_num(0,10,len(mnist_train))\n",
        "rand_num_test_label, rand_num_test_one_hot = rand_num(0,10,len(mnist_test))\n",
        "\n",
        "# rand_num_train_label = torch.randint(0,10,(len(mnist_train),))\n",
        "# rand_num_train = F.one_hot(rand_num_train_label)    \n",
        "# rand_num_test_label = torch.randint(0,10,(len(mnist_test),))\n",
        "# rand_num_test = F.one_hot(rand_num_test_label)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK-FDdeKLi-e",
        "outputId": "b60c5f6f-22d2-4918-dbff-0f224fd732aa"
      },
      "source": [
        "rand_num_train_label.shape, rand_num_train_one_hot.shape, rand_num_test_label.shape, rand_num_test_one_hot.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000]),\n",
              " torch.Size([60000, 10]),\n",
              " torch.Size([10000]),\n",
              " torch.Size([10000, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWlCe-g7bu8v"
      },
      "source": [
        "## Creating Actual Final Outputs of the newtork both for Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLRb1mUxLiqm",
        "outputId": "d64765d8-01f5-4016-8fad-6acf85cc773c"
      },
      "source": [
        "training_image_labels = mnist_train.train_labels\n",
        "training_sum_labels = mnist_train.train_labels + rand_num_train_label\n",
        "training_sum_labels_onehot = F.one_hot(training_sum_labels)\n",
        "\n",
        "print(f'Training data image number  : {training_image_labels}')\n",
        "print(f'Training data random number  : {rand_num_train_label}')\n",
        "print(f'Training data sum number : {training_sum_labels}')\n",
        "print('\\n')\n",
        "########## Test labels ###########################\n",
        "testing_image_labels = mnist_test.test_labels\n",
        "testing_sum_labels = mnist_test.test_labels + rand_num_test_label\n",
        "testing_sum_labels_onehot = F.one_hot(testing_sum_labels)\n",
        "\n",
        "print(f'Testing data image number  : {testing_image_labels}')\n",
        "print(f'Testing data random number  : {rand_num_test_label}')\n",
        "print(f'Testing data sum number : {testing_sum_labels}')\n",
        "print('\\n')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data image number  : tensor([5, 0, 4,  ..., 5, 6, 8])\n",
            "Training data random number  : tensor([5, 0, 3,  ..., 5, 9, 4])\n",
            "Training data sum number : tensor([10,  0,  7,  ..., 10, 15, 12])\n",
            "\n",
            "\n",
            "Testing data image number  : tensor([7, 2, 1,  ..., 4, 5, 6])\n",
            "Testing data random number  : tensor([5, 7, 1,  ..., 9, 8, 3])\n",
            "Testing data sum number : tensor([12,  9,  2,  ..., 13, 13,  9])\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:52: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63KzB2yuTOT1",
        "outputId": "80fd7ad1-c784-4c0a-f849-48e5fcab1d09"
      },
      "source": [
        "training_sum_labels_onehot[0].shape, testing_sum_labels_onehot[0].shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([19]), torch.Size([19]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XVKoigXScZm"
      },
      "source": [
        "# Fully Connected Network only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc20RnrRTcWY"
      },
      "source": [
        "## Converting images to single vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfTzJHPgHd_7",
        "outputId": "d709bbb1-d852-46d7-9168-50669cf3a131"
      },
      "source": [
        "def images_to_vector(data):\n",
        "  ''' \n",
        "  Converts 2d image tensor to 1d tensor \n",
        "  \n",
        "  Input: data --> contains the information aboue the image and its corresponding label\n",
        "\n",
        "  Output: img2vector --> tensor of size [Total_num_images, height_of_image * width_of_image]\n",
        "\n",
        "  '''\n",
        "  \n",
        "  img2vector = []\n",
        "  for images,labels in data:\n",
        "    img2vector.append(images.reshape(1,-1)) # list of tensors of shape [1,784]\n",
        "  img2vector = torch.stack(img2vector) # Stack converts a list of tensors in to a single tensor\n",
        "  print(f' length : {len(img2vector)}, shape of tensor {img2vector.shape}')\n",
        "  img2vector = torch.squeeze(img2vector) # Squeeze the tensor \n",
        "  print(f'img2vector shape after squeezing : {img2vector.shape}')\n",
        "  print('\\n')\n",
        "  return img2vector\n",
        "\n",
        "print(\"Training Data\")\n",
        "train_images = images_to_vector(mnist_train)\n",
        "\n",
        "print(\"Testing Data\")\n",
        "test_images = images_to_vector(mnist_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data\n",
            " length : 60000, shape of tensor torch.Size([60000, 1, 784])\n",
            "img2vector shape after squeezing : torch.Size([60000, 784])\n",
            "\n",
            "\n",
            "Testing Data\n",
            " length : 10000, shape of tensor torch.Size([10000, 1, 784])\n",
            "img2vector shape after squeezing : torch.Size([10000, 784])\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W9ZTa8Rqrr9"
      },
      "source": [
        "# TEst data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73uK1T-8qqqv"
      },
      "source": [
        "# test_images = []\n",
        "# #i=0\n",
        "# for im,la in mnist_test:\n",
        "#   test_images.append(im.reshape(1,-1)) # list of tensors of shape [1,784]\n",
        "#   #i += 1\n",
        "\n",
        "# test_images = torch.stack(test_images) # Stack converts a list of tensors in to a single tensor\n",
        "# print(f' length : {len(test_images)}, shape of tensor {test_images.shape}')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdFOfccpVKUe"
      },
      "source": [
        "## Concatenate the random number (one hot encoding) and Image data which is used as input to our Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHCrnmYpVJcD",
        "outputId": "6bbbd1a7-9970-4552-965b-7305b4cab545"
      },
      "source": [
        "# Training Inputs\n",
        "train_final = torch.cat((train_images,rand_num_train_one_hot),axis=1)\n",
        "train_final.shape # This is the final shape of the input that is passed to our Fully connected netowrk"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 794])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0Vq3dfrrOD1",
        "outputId": "643e439f-5d62-4cb8-c876-4b100fae9b21"
      },
      "source": [
        "#Testing Inputs\n",
        "test_final = torch.cat((test_images,rand_num_test_one_hot),axis=1)\n",
        "test_final.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 794])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEJ_LZgYWeFR"
      },
      "source": [
        "## Training & Testing Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ0IyX1BWhu3",
        "outputId": "594b5f78-bc37-4080-9d3a-947c1796dee5"
      },
      "source": [
        "# Training Outputs\n",
        "print(training_image_labels.shape)\n",
        "print(training_sum_labels.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000])\n",
            "torch.Size([60000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3wDvBMmUgGF",
        "outputId": "d38e1772-5057-4a5c-f20f-0c17dce2238d"
      },
      "source": [
        "training_image_labels"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4,  ..., 5, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOllBGyqG51"
      },
      "source": [
        "## Defining Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIYJtv69qGmG",
        "outputId": "4080defb-cfff-4755-c75d-c0b4cb543e9e"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Dataset is there to be able to interact with DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, image_input, label1, label2):\n",
        "    self.image_input = image_input\n",
        "\n",
        "    self.label1 = label1 # output of what number is present in the input image\n",
        "    self.label2 = label2 # number in the input image + number provided as input\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #sample = {'input':self.image_input[index],'output1':self.label1[index],'output2':self.label2[index]}\n",
        "    sample = (self.image_input[index],self.label1[index],self.label2[index])\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label1)\n",
        "\n",
        "myData_train = MyDataset(train_final,training_image_labels,training_sum_labels) #training_sum_labels_onehot) #\n",
        "\n",
        "for m in myData_train:\n",
        "  print(m)\n",
        "  break\n",
        "\n",
        "print()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118,\n",
            "        0.0706, 0.0706, 0.0706, 0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000,\n",
            "        0.9686, 0.4980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176, 0.1412, 0.3686, 0.6039,\n",
            "        0.6667, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8824, 0.6745, 0.9922,\n",
            "        0.9490, 0.7647, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.9333, 0.9922, 0.9922,\n",
            "        0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9843, 0.3647, 0.3216,\n",
            "        0.3216, 0.2196, 0.1529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.8588, 0.9922,\n",
            "        0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137, 0.9686, 0.9451, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3137,\n",
            "        0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000, 0.1686, 0.6039,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451,\n",
            "        0.8824, 0.6275, 0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.3176, 0.9412, 0.9922, 0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.1765, 0.7294, 0.9922, 0.9922, 0.5882, 0.1059, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.3647, 0.9882, 0.9922, 0.7333,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9765, 0.9922,\n",
            "        0.9765, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098, 0.7176, 0.9922,\n",
            "        0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922, 0.9922,\n",
            "        0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
            "        0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "        0.7765, 0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0706, 0.6706, 0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647,\n",
            "        0.3137, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.2157, 0.6745, 0.8863, 0.9922, 0.9922, 0.9922, 0.9922, 0.9569, 0.5216,\n",
            "        0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.5333, 0.9922, 0.9922, 0.9922, 0.8314, 0.5294, 0.5176, 0.0627,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000]), tensor(5), tensor(10))\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySrdJhljT0F4",
        "outputId": "cb5b9594-e134-4aba-9721-34816baf57c1"
      },
      "source": [
        "image, label1, label2 = next(iter(myData_train))\n",
        "image.shape, label1, label2"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([794]), tensor(5), tensor(10))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJlLVARLrXn4"
      },
      "source": [
        "# Testdata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVMSGoaBrXLy"
      },
      "source": [
        "myData_test = MyDataset(test_final,testing_image_labels,testing_sum_labels) #training_sum_labels_onehot) #\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCjclJNWcXHj"
      },
      "source": [
        "## Creating DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lys6RMYVqGh2",
        "outputId": "464e7168-f1f8-42da-dd7d-57e80ac5a31a"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "train_dataloader = DataLoader(myData_train, batch_size=100,shuffle=True, num_workers=0)\n",
        "for i_batch, sample_batched in enumerate(train_dataloader):\n",
        "    print(i_batch, sample_batched[0].size(),sample_batched[1].size(),sample_batched[2].size()) # index : 0 --> 1d tensor containing image and rand number information, \n",
        "    # 1 --> Output1 of the network which is number in the image, 2 --> Output2 of the network which is sum of the numbers in image and random number thats passed\n",
        "    break"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([100, 794]) torch.Size([100]) torch.Size([100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-fvwB2RrhQj",
        "outputId": "4851bddf-476f-45f0-d1a1-9b313f86ef9b"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "test_dataloader = DataLoader(myData_test, batch_size=10000,shuffle=True, num_workers=0)\n",
        "for i_batch, sample_batched in enumerate(test_dataloader):\n",
        "    print(i_batch, sample_batched[0].size(),sample_batched[1].size(),sample_batched[2].size())\n",
        "    break"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([10000, 794]) torch.Size([10000]) torch.Size([10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNwPHpKncgIT"
      },
      "source": [
        "# Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YrLFurHHd8t"
      },
      "source": [
        "class FCNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(in_features=794, out_features=512)\n",
        "    self.fc2 = nn.Linear(in_features=512, out_features=256)\n",
        "    self.fc3 = nn.Linear(in_features=256, out_features=64)\n",
        "    self.out1 = nn.Linear(in_features=64, out_features=10)\n",
        "    self.out2 = nn.Linear(in_features=64, out_features=19) #out_features=1 when predicting a number\n",
        "  \n",
        "  def forward(self,t):\n",
        "    # input layer\n",
        "    x = t\n",
        "\n",
        "    # fc1 layer\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # fc2 layer\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # fc3 layer\n",
        "    x = self.fc3(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # output1 layer\n",
        "    x1 = self.out1(x)\n",
        "    x1 = F.softmax(x1, dim=1)\n",
        "\n",
        "    # output1 layer\n",
        "    x2 = self.out2(x)\n",
        "    x2 = F.softmax(x2, dim=1) ### extra\n",
        "    return x1, x2    "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVUx3i6EaoKv",
        "outputId": "1788dbc1-5894-4226-acb0-1831ce9f79ac"
      },
      "source": [
        "model = FCNetwork()\n",
        "model"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FCNetwork(\n",
              "  (fc1): Linear(in_features=794, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc3): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (out1): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (out2): Linear(in_features=64, out_features=19, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLKHyqhN675A"
      },
      "source": [
        "## Get number of correct predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tKutLPJdib4"
      },
      "source": [
        "def get_num_correct(pred1, pred2, output1, output2):\n",
        "  num_correct_image_pred = pred1.argmax(dim=1).eq(output1).sum().item()\n",
        "  #num_correct_num_pred = pred2.eq(output2).sum().item() # if prediction is a pure number\n",
        "  num_correct_num_pred = pred2.argmax(dim=1).eq(output2).sum().item() # if output is onehot encoding\n",
        "  num_complete_correct_pred = min(num_correct_image_pred,num_correct_num_pred)\n",
        "  return num_correct_image_pred, num_correct_num_pred, num_complete_correct_pred"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg_FDnucan-9",
        "outputId": "80dd752c-05ff-497f-8225-7658074fbaa4"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(100):\n",
        "\n",
        "    total_loss = 0\n",
        "    total_correct_images = 0 # image input correct\n",
        "    total_correct_num = 0 # input number correct\n",
        "    total_all_correct = 0 # Both outputs correct\n",
        "\n",
        "    for batch in train_dataloader: # Get Batch\n",
        "      input = batch[0] # 0 --> 'input'\n",
        "      output1 = batch[1] # 1 --> 'output1'\n",
        "      output2 = batch[2] # 2 --> 'output2'\n",
        "\n",
        "      #print(f'Shape of input in loop : {input.shape}')\n",
        "      #print(f'Shape of output1 : {output1.shape}')\n",
        "      #print(f'Shape of output2 : {output2.shape}')\n",
        "\n",
        "      pred1,pred2 = model(input) # Pass Batch\n",
        "      loss1 = F.cross_entropy(pred1, output1) # Calculate Loss for number in image\n",
        "      loss2 = F.cross_entropy(pred2, output2) # Calculate Loss for number sent as input\n",
        "      #loss2 = F.mse_loss(pred2, output2.float()) # Calculate Loss for number sent as input\n",
        "      loss = loss1 + loss2\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward() # Calculate Gradients\n",
        "      optimizer.step() # Update Weights\n",
        "\n",
        "      total_loss += loss.item()\n",
        "      num_correct_image_pred, num_correct_num_pred, num_complete_correct_pred = get_num_correct(pred1, pred2, output1, output2)\n",
        "      total_correct_images += num_correct_image_pred\n",
        "      total_correct_num += num_correct_num_pred\n",
        "      total_all_correct += num_complete_correct_pred\n",
        "\n",
        "    print(\n",
        "    \"epoch\", epoch,\n",
        "    # \"actual_image: \",output1,\n",
        "    # \"pred_image: \", pred1,\n",
        "    #\"actual_sum: \", output2,\n",
        "    #\"pred_sum: \",pred2,\n",
        "    \"total_correct_images: \", total_correct_images,\n",
        "    \"total_correct_num: \", total_correct_num,\n",
        "    \"total_all_correct:\", total_all_correct, \n",
        "    \"loss:\", total_loss\n",
        "    )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 total_correct_images:  51776 total_correct_num:  6834 total_all_correct: 6834 loss: 2706.893977165222\n",
            "epoch 1 total_correct_images:  56376 total_correct_num:  17420 total_all_correct: 17420 loss: 2562.9400177001953\n",
            "epoch 2 total_correct_images:  57490 total_correct_num:  26550 total_all_correct: 26550 loss: 2458.039029121399\n",
            "epoch 3 total_correct_images:  58017 total_correct_num:  28047 total_all_correct: 28047 loss: 2434.7737271785736\n",
            "epoch 4 total_correct_images:  58388 total_correct_num:  28525 total_all_correct: 28525 loss: 2425.513831138611\n",
            "epoch 5 total_correct_images:  58606 total_correct_num:  29062 total_all_correct: 29062 loss: 2417.324357509613\n",
            "epoch 6 total_correct_images:  58782 total_correct_num:  29178 total_all_correct: 29178 loss: 2413.8988218307495\n",
            "epoch 7 total_correct_images:  58904 total_correct_num:  29273 total_all_correct: 29273 loss: 2411.394513607025\n",
            "epoch 8 total_correct_images:  58966 total_correct_num:  30871 total_all_correct: 30871 loss: 2395.2449939250946\n",
            "epoch 9 total_correct_images:  59088 total_correct_num:  31752 total_all_correct: 31752 loss: 2384.600048303604\n",
            "epoch 10 total_correct_images:  59192 total_correct_num:  33350 total_all_correct: 33350 loss: 2367.6563794612885\n",
            "epoch 11 total_correct_images:  59217 total_correct_num:  34000 total_all_correct: 34000 loss: 2360.3720891475677\n",
            "epoch 12 total_correct_images:  59287 total_correct_num:  35579 total_all_correct: 35579 loss: 2344.1289541721344\n",
            "epoch 13 total_correct_images:  59326 total_correct_num:  35754 total_all_correct: 35754 loss: 2341.525367975235\n",
            "epoch 14 total_correct_images:  59412 total_correct_num:  35776 total_all_correct: 35776 loss: 2340.1716113090515\n",
            "epoch 15 total_correct_images:  59444 total_correct_num:  35837 total_all_correct: 35837 loss: 2338.7250452041626\n",
            "epoch 16 total_correct_images:  59436 total_correct_num:  36427 total_all_correct: 36427 loss: 2333.2914493083954\n",
            "epoch 17 total_correct_images:  59461 total_correct_num:  37094 total_all_correct: 37094 loss: 2326.1987669467926\n",
            "epoch 18 total_correct_images:  59438 total_correct_num:  37098 total_all_correct: 37098 loss: 2326.3057680130005\n",
            "epoch 19 total_correct_images:  59534 total_correct_num:  37311 total_all_correct: 37311 loss: 2322.8840565681458\n",
            "epoch 20 total_correct_images:  59555 total_correct_num:  37723 total_all_correct: 37723 loss: 2318.3459944725037\n",
            "epoch 21 total_correct_images:  59539 total_correct_num:  37707 total_all_correct: 37707 loss: 2318.5191571712494\n",
            "epoch 22 total_correct_images:  59584 total_correct_num:  38032 total_all_correct: 38032 loss: 2315.015300989151\n",
            "epoch 23 total_correct_images:  59566 total_correct_num:  39863 total_all_correct: 39863 loss: 2297.7329399585724\n",
            "epoch 24 total_correct_images:  59587 total_correct_num:  40058 total_all_correct: 40058 loss: 2295.062532901764\n",
            "epoch 25 total_correct_images:  59608 total_correct_num:  40672 total_all_correct: 40672 loss: 2288.9900064468384\n",
            "epoch 26 total_correct_images:  59637 total_correct_num:  42628 total_all_correct: 42628 loss: 2269.7466480731964\n",
            "epoch 27 total_correct_images:  59632 total_correct_num:  42967 total_all_correct: 42967 loss: 2266.055933237076\n",
            "epoch 28 total_correct_images:  59606 total_correct_num:  42973 total_all_correct: 42973 loss: 2266.233340740204\n",
            "epoch 29 total_correct_images:  59631 total_correct_num:  44687 total_all_correct: 44687 loss: 2249.6097598075867\n",
            "epoch 30 total_correct_images:  59673 total_correct_num:  45208 total_all_correct: 45208 loss: 2243.665789604187\n",
            "epoch 31 total_correct_images:  59672 total_correct_num:  46525 total_all_correct: 46525 loss: 2231.0167274475098\n",
            "epoch 32 total_correct_images:  59690 total_correct_num:  46672 total_all_correct: 46672 loss: 2229.1498782634735\n",
            "epoch 33 total_correct_images:  59653 total_correct_num:  46786 total_all_correct: 46786 loss: 2228.409299135208\n",
            "epoch 34 total_correct_images:  59701 total_correct_num:  47232 total_all_correct: 47232 loss: 2223.5541718006134\n",
            "epoch 35 total_correct_images:  59722 total_correct_num:  47272 total_all_correct: 47272 loss: 2222.7283732891083\n",
            "epoch 36 total_correct_images:  59752 total_correct_num:  47279 total_all_correct: 47279 loss: 2222.2700715065002\n",
            "epoch 37 total_correct_images:  59682 total_correct_num:  47840 total_all_correct: 47840 loss: 2217.941302537918\n",
            "epoch 38 total_correct_images:  59707 total_correct_num:  47872 total_all_correct: 47872 loss: 2217.1210873126984\n",
            "epoch 39 total_correct_images:  59711 total_correct_num:  47931 total_all_correct: 47931 loss: 2216.628655195236\n",
            "epoch 40 total_correct_images:  59700 total_correct_num:  48474 total_all_correct: 48474 loss: 2211.3415143489838\n",
            "epoch 41 total_correct_images:  59733 total_correct_num:  48519 total_all_correct: 48519 loss: 2210.3604061603546\n",
            "epoch 42 total_correct_images:  59739 total_correct_num:  48526 total_all_correct: 48526 loss: 2210.1799697875977\n",
            "epoch 43 total_correct_images:  59696 total_correct_num:  48493 total_all_correct: 48493 loss: 2211.0002057552338\n",
            "epoch 44 total_correct_images:  59712 total_correct_num:  48497 total_all_correct: 48497 loss: 2210.7738630771637\n",
            "epoch 45 total_correct_images:  59723 total_correct_num:  48532 total_all_correct: 48532 loss: 2210.3141362667084\n",
            "epoch 46 total_correct_images:  59765 total_correct_num:  48646 total_all_correct: 48646 loss: 2208.631982088089\n",
            "epoch 47 total_correct_images:  59770 total_correct_num:  49168 total_all_correct: 49168 loss: 2203.5956592559814\n",
            "epoch 48 total_correct_images:  59774 total_correct_num:  49199 total_all_correct: 49199 loss: 2203.152496576309\n",
            "epoch 49 total_correct_images:  59803 total_correct_num:  49213 total_all_correct: 49213 loss: 2202.6187872886658\n",
            "epoch 50 total_correct_images:  59726 total_correct_num:  49143 total_all_correct: 49143 loss: 2204.29643201828\n",
            "epoch 51 total_correct_images:  59743 total_correct_num:  49169 total_all_correct: 49169 loss: 2203.8952498435974\n",
            "epoch 52 total_correct_images:  59763 total_correct_num:  49187 total_all_correct: 49187 loss: 2203.5142574310303\n",
            "epoch 53 total_correct_images:  59736 total_correct_num:  49155 total_all_correct: 49155 loss: 2204.20321893692\n",
            "epoch 54 total_correct_images:  59745 total_correct_num:  49815 total_all_correct: 49815 loss: 2197.706736803055\n",
            "epoch 55 total_correct_images:  59753 total_correct_num:  49831 total_all_correct: 49831 loss: 2197.22044301033\n",
            "epoch 56 total_correct_images:  59757 total_correct_num:  49830 total_all_correct: 49830 loss: 2197.2688553333282\n",
            "epoch 57 total_correct_images:  59753 total_correct_num:  49817 total_all_correct: 49817 loss: 2197.326549053192\n",
            "epoch 58 total_correct_images:  59729 total_correct_num:  49814 total_all_correct: 49814 loss: 2197.7433338165283\n",
            "epoch 59 total_correct_images:  59767 total_correct_num:  49823 total_all_correct: 49823 loss: 2197.1395769119263\n",
            "epoch 60 total_correct_images:  59800 total_correct_num:  50589 total_all_correct: 50589 loss: 2189.4022874832153\n",
            "epoch 61 total_correct_images:  59773 total_correct_num:  50999 total_all_correct: 50999 loss: 2185.7348980903625\n",
            "epoch 62 total_correct_images:  59804 total_correct_num:  51011 total_all_correct: 51011 loss: 2185.150866985321\n",
            "epoch 63 total_correct_images:  59772 total_correct_num:  51002 total_all_correct: 51002 loss: 2185.608098268509\n",
            "epoch 64 total_correct_images:  59761 total_correct_num:  50988 total_all_correct: 50988 loss: 2185.836010456085\n",
            "epoch 65 total_correct_images:  59792 total_correct_num:  50998 total_all_correct: 50998 loss: 2185.4343111515045\n",
            "epoch 66 total_correct_images:  59811 total_correct_num:  51040 total_all_correct: 51040 loss: 2184.671064853668\n",
            "epoch 67 total_correct_images:  59791 total_correct_num:  51030 total_all_correct: 51030 loss: 2185.0084207057953\n",
            "epoch 68 total_correct_images:  59814 total_correct_num:  51023 total_all_correct: 51023 loss: 2184.941510915756\n",
            "epoch 69 total_correct_images:  59742 total_correct_num:  50959 total_all_correct: 50959 loss: 2186.345725297928\n",
            "epoch 70 total_correct_images:  59788 total_correct_num:  51018 total_all_correct: 51018 loss: 2185.174047470093\n",
            "epoch 71 total_correct_images:  59821 total_correct_num:  51044 total_all_correct: 51044 loss: 2184.496706008911\n",
            "epoch 72 total_correct_images:  59779 total_correct_num:  51005 total_all_correct: 51005 loss: 2185.444187641144\n",
            "epoch 73 total_correct_images:  59782 total_correct_num:  51007 total_all_correct: 51007 loss: 2185.531259059906\n",
            "epoch 74 total_correct_images:  59768 total_correct_num:  51072 total_all_correct: 51072 loss: 2185.006820678711\n",
            "epoch 75 total_correct_images:  59825 total_correct_num:  51598 total_all_correct: 51598 loss: 2179.1049213409424\n",
            "epoch 76 total_correct_images:  59844 total_correct_num:  51623 total_all_correct: 51623 loss: 2178.53852725029\n",
            "epoch 77 total_correct_images:  59765 total_correct_num:  51549 total_all_correct: 51549 loss: 2180.243727684021\n",
            "epoch 78 total_correct_images:  59829 total_correct_num:  51588 total_all_correct: 51588 loss: 2179.144842147827\n",
            "epoch 79 total_correct_images:  59786 total_correct_num:  51580 total_all_correct: 51580 loss: 2179.69171833992\n",
            "epoch 80 total_correct_images:  59776 total_correct_num:  51567 total_all_correct: 51567 loss: 2180.044689178467\n",
            "epoch 81 total_correct_images:  59801 total_correct_num:  51588 total_all_correct: 51588 loss: 2179.5800223350525\n",
            "epoch 82 total_correct_images:  59797 total_correct_num:  51574 total_all_correct: 51574 loss: 2179.731798887253\n",
            "epoch 83 total_correct_images:  59835 total_correct_num:  51606 total_all_correct: 51606 loss: 2178.9242701530457\n",
            "epoch 84 total_correct_images:  59814 total_correct_num:  51596 total_all_correct: 51596 loss: 2179.1635851860046\n",
            "epoch 85 total_correct_images:  59860 total_correct_num:  51629 total_all_correct: 51629 loss: 2178.372240781784\n",
            "epoch 86 total_correct_images:  59796 total_correct_num:  51568 total_all_correct: 51568 loss: 2179.7503502368927\n",
            "epoch 87 total_correct_images:  59839 total_correct_num:  51605 total_all_correct: 51605 loss: 2178.8478996753693\n",
            "epoch 88 total_correct_images:  59863 total_correct_num:  51633 total_all_correct: 51633 loss: 2178.267034292221\n",
            "epoch 89 total_correct_images:  59799 total_correct_num:  51576 total_all_correct: 51576 loss: 2179.6119437217712\n",
            "epoch 90 total_correct_images:  59798 total_correct_num:  51578 total_all_correct: 51578 loss: 2179.5744304656982\n",
            "epoch 91 total_correct_images:  59788 total_correct_num:  51569 total_all_correct: 51569 loss: 2179.861364364624\n",
            "epoch 92 total_correct_images:  59847 total_correct_num:  51622 total_all_correct: 51622 loss: 2178.6095967292786\n",
            "epoch 93 total_correct_images:  59809 total_correct_num:  51594 total_all_correct: 51594 loss: 2179.2687599658966\n",
            "epoch 94 total_correct_images:  59831 total_correct_num:  51601 total_all_correct: 51601 loss: 2179.0460872650146\n",
            "epoch 95 total_correct_images:  59835 total_correct_num:  51603 total_all_correct: 51603 loss: 2178.8332607746124\n",
            "epoch 96 total_correct_images:  59780 total_correct_num:  51557 total_all_correct: 51557 loss: 2180.021612882614\n",
            "epoch 97 total_correct_images:  59820 total_correct_num:  51611 total_all_correct: 51611 loss: 2179.0087723731995\n",
            "epoch 98 total_correct_images:  59855 total_correct_num:  51630 total_all_correct: 51630 loss: 2178.370864391327\n",
            "epoch 99 total_correct_images:  59773 total_correct_num:  51544 total_all_correct: 51544 loss: 2180.266545534134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVyov9AXcVpd"
      },
      "source": [
        "# print(f'lr_vs_loss : {lr_vs_loss}')\n",
        "# print(f'lr_vs_correct : {lr_vs_correct}')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_O4Qvs0Vx49"
      },
      "source": [
        "# Predictions on Testset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9WqrCiwXTeV",
        "outputId": "82ae033f-73ff-4066-de6f-81bd067554ac"
      },
      "source": [
        "total_correct_images_test = []\n",
        "total_correct_num_test = []\n",
        "total_all_correct_test = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "   # Get Batch\n",
        "  input_test = batch[0] # 0 --> ['input']\n",
        "  output1_test = batch[1] # 1 --> ['output1']\n",
        "  output2_test = batch[2] # 2 --> ['output2']\n",
        "\n",
        "  print(f'Shape of input in loop : {input_test.shape}')\n",
        "  print(f'Shape of output1 : {output1_test.shape}')\n",
        "  print(f'Shape of output2 : {output2_test.shape}')\n",
        "\n",
        "  pred1_test,pred2_test = model(input_test) # Pass Batch\n",
        "  print(f' Sum of numbers Predictions from netowrk : {pred2_test.argmax(dim=1)}') #.eq(output2).sum().item())\n",
        "  print(f' Sum of numbers Actual numbers : {output2_test}')\n",
        "  print('\\n')\n",
        "  print(f'Total number of samples with correct output1 predictions : {pred1_test.argmax(dim=1).eq(output1_test).sum().item()}')\n",
        "  print('\\n')\n",
        "  print(f'Total number of samples with correct output2 predictions : {pred2_test.argmax(dim=1).eq(output2_test).sum().item()}')\n",
        "  print('\\n')\n",
        "  \n",
        "  # num_correct_image_pred, num_correct_num_pred, num_complete_correct_pred = get_num_correct(pred1_test, pred2_test, output1_test, output2_test)\n",
        "  # total_correct_images_test += num_correct_image_pred\n",
        "  # total_correct_num_test += num_correct_num_pred\n",
        "  # total_all_correct_test += num_complete_correct_pred\n",
        "\n",
        "  #break\n",
        "\n",
        "print(\n",
        "\"total_correct_images: \", total_correct_images_test,\n",
        "\"total_correct_num: \", total_correct_num_test,\n",
        "\"total_all_correct:\", total_all_correct_test, \n",
        ")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of input in loop : torch.Size([10000, 794])\n",
            "Shape of output1 : torch.Size([10000])\n",
            "Shape of output2 : torch.Size([10000])\n",
            " Sum of numbers Predictions from netowrk : tensor([ 9, 16,  8,  ...,  8,  6,  9])\n",
            " Sum of numbers Actual numbers : tensor([ 7, 16, 15,  ...,  8,  6,  9])\n",
            "\n",
            "\n",
            "Total number of samples with correct output1 predictions : 9791\n",
            "\n",
            "\n",
            "Total number of samples with correct output2 predictions : 8433\n",
            "\n",
            "\n",
            "total_correct_images:  [] total_correct_num:  [] total_all_correct: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlSK8B0xVrYG"
      },
      "source": [
        "# epochs=100, training_batch_size = 1000\n",
        "# Shape of input in loop : torch.Size([10000, 794])\n",
        "# Shape of output1 : torch.Size([10000])\n",
        "# Shape of output2 : torch.Size([10000])\n",
        "#  Sum of numbers Predictions from netowrk : tensor([ 4,  7,  9,  ...,  8,  6, 11])\n",
        "#  Sum of numbers Actual numbers : tensor([ 4,  2,  9,  ..., 15,  6, 13])\n",
        "\n",
        "\n",
        "# Total number of samples with correct output1 predictions : 9781\n",
        "\n",
        "\n",
        "# Total number of samples with correct output2 predictions : 5871\n",
        "\n",
        "\n",
        "# total_correct_images:  [] total_correct_num:  [] total_all_correct: []\n",
        "#*****************************************************************************************************************\n",
        "# epochs=200, training_batch_size = 1000\n",
        "# Shape of input in loop : torch.Size([10000, 794])\n",
        "# Shape of output1 : torch.Size([10000])\n",
        "# Shape of output2 : torch.Size([10000])\n",
        "#  Sum of numbers Predictions from netowrk : tensor([14,  5,  9,  ...,  3,  9, 12])\n",
        "#  Sum of numbers Actual numbers : tensor([14,  5,  9,  ...,  3,  9, 12])\n",
        "\n",
        "\n",
        "# Total number of samples with correct output1 predictions : 9828\n",
        "\n",
        "\n",
        "# Total number of samples with correct output2 predictions : 7885\n",
        "\n",
        "\n",
        "# total_correct_images:  [] total_correct_num:  [] total_all_correct: []\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAdiXJgLVcnz"
      },
      "source": [
        "## Saves the model\n",
        "torch.save(model, 'trained_model.pth')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRiUWZt0aRsF"
      },
      "source": [
        "## Loading the saved model\n",
        "model1 = torch.load('trained_model.pth')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E81NUCx6qGVB"
      },
      "source": [
        "## Predictions on test set\n",
        "pred1_1_test,pred2_1_test = model1(input_test)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kf-PMa3diYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e579a7-b25f-4bfb-85d4-2638375a9644"
      },
      "source": [
        "pred1_1_test"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00],\n",
              "        [6.6328e-40, 2.8540e-29, 1.5644e-31,  ..., 1.0000e+00, 3.8173e-25,\n",
              "         8.0742e-34],\n",
              "        [2.4363e-38, 2.2459e-40, 0.0000e+00,  ..., 4.7504e-42, 1.0000e+00,\n",
              "         5.9791e-30],\n",
              "        ...,\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.0000e+00,\n",
              "         0.0000e+00],\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00],\n",
              "        [1.8793e-37, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.7002e-41,\n",
              "         1.0000e+00]], grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmlQHReldiOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba802c9-f505-4f23-d48d-6db7b0087313"
      },
      "source": [
        "output1_num_correct_image_pred = pred1_1_test.argmax(dim=1).eq(output1_test).sum().item()\n",
        "output2_num_correct_num_pred = pred2_1_test.argmax(dim=1).eq(output2_test).sum().item()\n",
        "\n",
        "print(f'% of correct Output1 predictions : {output1_num_correct_image_pred*100/len(output1_test)}%')\n",
        "print(f'% of correct Output2 predictions : {output2_num_correct_num_pred*100/len(output1_test)}%')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of correct Output1 predictions : 97.91%\n",
            "% of correct Output2 predictions : 84.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTLYIBHzaoGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36820656-01f3-45eb-ac85-89cd37c9570a"
      },
      "source": [
        "len(output1_test)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k_qYE4IaoDW"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}